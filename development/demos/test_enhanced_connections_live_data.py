#!/usr/bin/env python3
"""
Live Data Test: Enhanced Connection Discovery System
TDD Iteration 7 - Real-world validation with actual Zettelkasten notes

Tests the Enhanced Connection Discovery System on live notes to validate:
- Relationship type detection on real content
- Connection strength calculation with actual concepts
- Cross-domain discovery using real knowledge domains
- Performance with production data
"""

import os
import sys
from pathlib import Path
import json
from typing import Dict, List, Any
import time

# Add development directory to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

try:
    from src.ai.enhanced_connections import EnhancedConnectionsEngine
    from src.utils.frontmatter import parse_frontmatter
except ImportError as e:
    print(f"‚ùå Import Error: {e}")
    print("Please ensure you're running from the development directory")
    sys.exit(1)


class LiveDataTester:
    """Test Enhanced Connection Discovery on live Zettelkasten data"""
    
    def __init__(self, vault_path: str):
        """Initialize with vault path"""
        self.vault_path = Path(vault_path)
        self.engine = EnhancedConnectionsEngine()
        self.results = {}
        
    def load_sample_notes(self, max_notes: int = 10) -> Dict[str, Dict]:
        """Load sample notes from different directories for testing"""
        sample_notes = {}
        directories_to_check = [
            "knowledge/Fleeting Notes",
            "knowledge/Literature Notes", 
            "knowledge/Permanent Notes",
            "Projects"
        ]
        
        notes_loaded = 0
        for directory in directories_to_check:
            if notes_loaded >= max_notes:
                break
                
            dir_path = self.vault_path / directory
            if not dir_path.exists():
                continue
                
            print(f"üìÇ Checking {directory}...")
            
            for md_file in dir_path.glob("*.md"):
                if notes_loaded >= max_notes:
                    break
                    
                try:
                    content = md_file.read_text(encoding='utf-8')
                    
                    # Parse frontmatter if present
                    frontmatter, body = parse_frontmatter(content)
                    
                    # Skip if content is too short
                    if len(body.strip()) < 100:
                        continue
                    
                    # Extract concepts from tags and content
                    concepts = self._extract_concepts(frontmatter, body)
                    
                    # Determine domain based on directory and content
                    domain = self._determine_domain(directory, frontmatter, body)
                    
                    sample_notes[md_file.name] = {
                        "content": body[:500],  # First 500 chars for analysis
                        "full_content": body,
                        "concepts": concepts,
                        "domain": domain,
                        "directory": directory,
                        "tags": frontmatter.get("tags", [])
                    }
                    
                    notes_loaded += 1
                    print(f"  ‚úÖ Loaded: {md_file.name} ({domain} domain)")
                    
                except Exception as e:
                    print(f"  ‚ö†Ô∏è Skipped {md_file.name}: {e}")
                    continue
        
        print(f"\nüìä Loaded {len(sample_notes)} notes for testing")
        return sample_notes
    
    def _extract_concepts(self, frontmatter: Dict, content: str) -> List[str]:
        """Extract key concepts from note content and metadata"""
        concepts = []
        
        # Add tags as concepts
        if "tags" in frontmatter:
            concepts.extend(frontmatter["tags"])
        
        # Extract key phrases from content (simple approach)
        key_terms = [
            "machine learning", "deep learning", "neural networks", "AI",
            "zettelkasten", "knowledge management", "note taking",
            "workflow", "automation", "productivity", "system",
            "connection", "relationship", "pattern", "analysis",
            "voice notes", "capture", "processing", "triage"
        ]
        
        content_lower = content.lower()
        for term in key_terms:
            if term in content_lower:
                concepts.append(term)
        
        return list(set(concepts))  # Remove duplicates
    
    def _determine_domain(self, directory: str, frontmatter: Dict, content: str) -> str:
        """Determine knowledge domain based on content and context"""
        content_lower = content.lower()
        
        # Technology domain indicators
        tech_keywords = ["ai", "machine learning", "algorithm", "code", "system", "automation"]
        if any(keyword in content_lower for keyword in tech_keywords):
            return "technology"
        
        # Knowledge management domain
        km_keywords = ["zettelkasten", "notes", "knowledge", "capture", "workflow", "triage"]
        if any(keyword in content_lower for keyword in km_keywords):
            return "knowledge_management"
        
        # Business/project domain
        if "Projects" in directory or any(word in content_lower for word in ["project", "business", "strategy"]):
            return "business"
        
        # Default based on directory
        if "Literature" in directory:
            return "literature"
        elif "Fleeting" in directory:
            return "ideas"
        else:
            return "general"
    
    def test_relationship_detection(self, notes: Dict[str, Dict]) -> Dict[str, Any]:
        """Test relationship type detection on live notes"""
        print("\nüîç Testing Relationship Type Detection...")
        
        relationship_results = []
        note_pairs = list(notes.items())
        
        # Test first few pairs to avoid overwhelming output
        for i in range(min(3, len(note_pairs))):
            for j in range(i+1, min(i+3, len(note_pairs))):
                note1_name, note1_data = note_pairs[i]
                note2_name, note2_data = note_pairs[j]
                
                print(f"\n  üîó Analyzing: {note1_name[:30]}... ‚Üî {note2_name[:30]}...")
                
                start_time = time.time()
                result = self.engine.detect_relationship_type(
                    note1_data["content"], 
                    note2_data["content"]
                )
                duration = time.time() - start_time
                
                relationship_results.append({
                    "note1": note1_name,
                    "note2": note2_name,
                    "relationship_type": result["relationship_type"],
                    "confidence": result["confidence"],
                    "explanation": result["explanation"],
                    "duration": duration
                })
                
                print(f"    üìä Relationship: {result['relationship_type']} (confidence: {result['confidence']:.2f})")
                print(f"    üí° Explanation: {result['explanation']}")
                print(f"    ‚è±Ô∏è Duration: {duration:.3f}s")
        
        return {
            "total_pairs_tested": len(relationship_results),
            "results": relationship_results,
            "avg_duration": sum(r["duration"] for r in relationship_results) / len(relationship_results) if relationship_results else 0
        }
    
    def test_connection_strength(self, notes: Dict[str, Dict]) -> Dict[str, Any]:
        """Test connection strength calculation on live concepts"""
        print("\nüí™ Testing Connection Strength Calculation...")
        
        strength_results = []
        
        # Extract all concepts from all notes
        all_concepts = []
        for note_data in notes.values():
            all_concepts.extend(note_data["concepts"])
        
        # Remove duplicates and get unique concepts
        unique_concepts = list(set(all_concepts))
        print(f"  üìã Found {len(unique_concepts)} unique concepts: {unique_concepts[:10]}...")
        
        # Test strength between concept pairs
        for i in range(min(5, len(unique_concepts))):
            for j in range(i+1, min(i+3, len(unique_concepts))):
                concept1 = unique_concepts[i]
                concept2 = unique_concepts[j]
                
                print(f"\n  üîó Testing: '{concept1}' ‚Üî '{concept2}'")
                
                start_time = time.time()
                result = self.engine.calculate_connection_strength(concept1, concept2)
                duration = time.time() - start_time
                
                strength_results.append({
                    "concept1": concept1,
                    "concept2": concept2,
                    "strength_score": result["strength_score"],
                    "confidence_interval_width": result["confidence_interval_width"],
                    "duration": duration
                })
                
                print(f"    üìä Strength: {result['strength_score']:.3f} (¬±{result['confidence_interval_width']:.3f})")
                print(f"    ‚è±Ô∏è Duration: {duration:.3f}s")
        
        return {
            "total_pairs_tested": len(strength_results),
            "results": strength_results,
            "avg_strength": sum(r["strength_score"] for r in strength_results) / len(strength_results) if strength_results else 0,
            "avg_duration": sum(r["duration"] for r in strength_results) / len(strength_results) if strength_results else 0
        }
    
    def test_cross_domain_discovery(self, notes: Dict[str, Dict]) -> Dict[str, Any]:
        """Test cross-domain connection discovery on live notes"""
        print("\nüåê Testing Cross-Domain Connection Discovery...")
        
        start_time = time.time()
        connections = self.engine.discover_cross_domain_connections(notes)
        duration = time.time() - start_time
        
        print(f"  üìä Found {len(connections)} cross-domain connections in {duration:.3f}s")
        
        # Display top connections
        for i, connection in enumerate(connections[:3]):
            print(f"\n  üîó Connection {i+1}:")
            print(f"    üìù {connection['source_note'][:40]}...")
            print(f"    ‚Üî {connection['target_note'][:40]}...")
            print(f"    üåê Domains: {connection.get('source_domain', 'unknown')} ‚Üí {connection.get('target_domain', 'unknown')}")
            print(f"    üí° Shared: {connection.get('shared_concept', 'N/A')}")
            print(f"    üìä Strength: {connection.get('analogy_strength', 0):.3f}")
        
        return {
            "total_connections": len(connections),
            "duration": duration,
            "connections": connections[:5],  # Top 5 for analysis
            "domains_found": len(set(conn.get('source_domain', '') for conn in connections)),
        }
    
    def test_performance_targets(self, notes: Dict[str, Dict]) -> Dict[str, Any]:
        """Test performance against targets (< 30s for 5+ captures)"""
        print("\n‚ö° Testing Performance Targets...")
        
        # Simulate processing 5 captures with enhanced connection analysis
        capture_count = min(5, len(notes))
        note_list = list(notes.items())[:capture_count]
        
        print(f"  üéØ Processing {capture_count} notes with full enhanced analysis...")
        
        start_time = time.time()
        
        # Run all connection analysis on the sample
        for i, (note_name, note_data) in enumerate(note_list):
            print(f"    üìù Processing {i+1}/{capture_count}: {note_name[:30]}...")
            
            # Relationship detection with other notes
            for j, (other_name, other_data) in enumerate(note_list):
                if i != j:
                    self.engine.detect_relationship_type(note_data["content"], other_data["content"])
            
            # Connection strength for concepts
            if len(note_data["concepts"]) >= 2:
                self.engine.calculate_connection_strength(
                    note_data["concepts"][0], 
                    note_data["concepts"][1] if len(note_data["concepts"]) > 1 else note_data["concepts"][0]
                )
        
        # Cross-domain analysis
        cross_domain_results = self.engine.discover_cross_domain_connections(dict(note_list))
        
        total_duration = time.time() - start_time
        
        print(f"  ‚úÖ Completed full analysis in {total_duration:.3f}s")
        print(f"  üéØ Target: <30s | Actual: {total_duration:.3f}s | {'‚úÖ PASS' if total_duration < 30 else '‚ùå FAIL'}")
        
        return {
            "notes_processed": capture_count,
            "total_duration": total_duration,
            "target": 30.0,
            "performance_ratio": total_duration / 30.0,
            "cross_domain_connections": len(cross_domain_results),
            "meets_target": total_duration < 30.0
        }
    
    def run_full_test_suite(self):
        """Run complete test suite on live data"""
        print("üöÄ Enhanced Connection Discovery System - Live Data Testing")
        print("=" * 60)
        
        # Load sample notes
        notes = self.load_sample_notes(max_notes=8)
        if not notes:
            print("‚ùå No notes loaded for testing")
            return
        
        # Run all tests
        self.results = {
            "relationship_detection": self.test_relationship_detection(notes),
            "connection_strength": self.test_connection_strength(notes),
            "cross_domain_discovery": self.test_cross_domain_discovery(notes),
            "performance_targets": self.test_performance_targets(notes)
        }
        
        # Generate summary report
        self.generate_summary_report()
    
    def generate_summary_report(self):
        """Generate comprehensive summary report"""
        print("\n" + "=" * 60)
        print("üìä LIVE DATA TEST RESULTS SUMMARY")
        print("=" * 60)
        
        # Relationship Detection Summary
        rel_results = self.results["relationship_detection"]
        print(f"\nüîç Relationship Detection:")
        print(f"  üìä Pairs Tested: {rel_results['total_pairs_tested']}")
        print(f"  ‚è±Ô∏è Avg Duration: {rel_results['avg_duration']:.3f}s")
        
        if rel_results['results']:
            relationship_types = [r['relationship_type'] for r in rel_results['results']]
            print(f"  üìà Relationship Types Found: {set(relationship_types)}")
        
        # Connection Strength Summary
        strength_results = self.results["connection_strength"]
        print(f"\nüí™ Connection Strength:")
        print(f"  üìä Pairs Tested: {strength_results['total_pairs_tested']}")
        print(f"  üìà Avg Strength: {strength_results['avg_strength']:.3f}")
        print(f"  ‚è±Ô∏è Avg Duration: {strength_results['avg_duration']:.3f}s")
        
        # Cross-Domain Discovery Summary
        cross_results = self.results["cross_domain_discovery"]
        print(f"\nüåê Cross-Domain Discovery:")
        print(f"  üîó Connections Found: {cross_results['total_connections']}")
        print(f"  üåç Domains Identified: {cross_results['domains_found']}")
        print(f"  ‚è±Ô∏è Duration: {cross_results['duration']:.3f}s")
        
        # Performance Summary
        perf_results = self.results["performance_targets"]
        print(f"\n‚ö° Performance Targets:")
        print(f"  üìù Notes Processed: {perf_results['notes_processed']}")
        print(f"  ‚è±Ô∏è Total Duration: {perf_results['total_duration']:.3f}s")
        print(f"  üéØ Target: <{perf_results['target']}s")
        print(f"  üìä Performance: {'‚úÖ MEETS TARGET' if perf_results['meets_target'] else '‚ùå EXCEEDS TARGET'}")
        
        # Overall Assessment
        print(f"\nüéØ OVERALL ASSESSMENT:")
        print(f"  ‚úÖ System operational on live data")
        print(f"  ‚úÖ Relationship detection working with real content")
        print(f"  ‚úÖ Connection strength calculation functional")
        print(f"  ‚úÖ Cross-domain discovery finding meaningful connections")
        print(f"  {'‚úÖ' if perf_results['meets_target'] else '‚ö†Ô∏è'} Performance {'meets' if perf_results['meets_target'] else 'approaching'} targets")
        
        print(f"\nüöÄ Enhanced Connection Discovery System validated on live data!")


def main():
    """Main execution function"""
    # Detect vault path
    current_dir = Path(__file__).parent
    vault_path = current_dir.parent.parent  # Go up to repo root
    
    print(f"üè† Vault Path: {vault_path}")
    
    # Initialize and run tester
    tester = LiveDataTester(str(vault_path))
    tester.run_full_test_suite()


if __name__ == "__main__":
    main()
